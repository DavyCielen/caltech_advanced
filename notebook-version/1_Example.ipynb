{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# Langchain stuffs\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally set your OpenAI API key in code (not recommended for production):\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"<YOUR_OPENAI_KEY>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Tools\n",
    "Thinks of it like the \"goals\" that we want the agent to do for us. We won't need to hardcode anymore. We just guide the agent to do it for us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Check inventory tool\n",
    " - Update inventory tool\n",
    " - Schedule inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def check_inventory(item: str) -> str:\n",
    "    \"\"\"\n",
    "    Mock function to query item stock levels.\n",
    "    In production, you'd query a real database or ERP system.\n",
    "    \"\"\"\n",
    "    mock_db = {\"widget-a\": 20, \"widget-b\": 0, \"widget-c\": 100}\n",
    "    key = item.lower()\n",
    "    if key in mock_db:\n",
    "        qty = mock_db[key]\n",
    "        if qty > 0:\n",
    "            return f\"[Inventory] '{item}' in stock: {qty} units.\"\n",
    "        else:\n",
    "            return f\"[Inventory] '{item}' is out of stock.\"\n",
    "    return f\"[Inventory] No data for '{item}'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def update_inventory(args: str) -> str:\n",
    "    \"\"\"\n",
    "    Mock function to 'add' a certain quantity to a given item.\n",
    "    Usage example: \"widget-a, 50\"\n",
    "    In a real system, you'd parse carefully or use a Pydantic model + DB updates.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        item_str, qty_str = args.split(\",\")\n",
    "        item_str = item_str.strip().lower()\n",
    "        qty = int(qty_str.strip())\n",
    "        return f\"[Update] Successfully added {qty} units of '{item_str}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"[Update] Error parsing input: {args}. ({e})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def schedule_delivery(order_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Mock function to schedule a delivery for a given order ID.\n",
    "    In practice, you'd call a shipping or 3PL API.\n",
    "    \"\"\"\n",
    "    if not order_id:\n",
    "        return \"[Delivery] Missing order ID.\"\n",
    "    return f\"[Delivery] Scheduled shipment for order '{order_id}' on next truck run.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",    # or \"gpt-4\" / \"gpt-3.5-turbo\" / custom endpoint\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # api_key=\"...\",     # Only if you prefer passing the key directly\n",
    "    # base_url=\"...\",    # e.g. self-hosted instance or custom proxy\n",
    "    # organization=\"...\",# or other config parameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional memory for multi-turn conversations\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_app = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=[check_inventory, update_inventory, schedule_delivery],\n",
    "    checkpointer=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Check inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- EXAMPLE 1: Check Inventory ---\")\n",
    "user_input_1 = \"Check inventory for widget-a please.\"\n",
    "result_1 = agent_app.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input_1}]},\n",
    "    config={\"configurable\": {\"thread_id\": THREAD_ID}}\n",
    ")\n",
    "print(\"AGENT RESPONSE:\", result_1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Update inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- EXAMPLE 2: Update Inventory ---\")\n",
    "user_input_2 = \"Add 50 units of widget-b to inventory.\"\n",
    "result_2 = agent_app.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input_2}]},\n",
    "    config={\"configurable\": {\"thread_id\": THREAD_ID}}\n",
    ")\n",
    "print(\"AGENT RESPONSE:\", result_2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Schedule a delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- EXAMPLE 3: Schedule a Delivery ---\")\n",
    "user_input_3 = \"Now schedule a delivery for order #12345.\"\n",
    "result_3 = agent_app.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input_3}]},\n",
    "    config={\"configurable\": {\"thread_id\": THREAD_ID}}\n",
    ")\n",
    "print(\"AGENT RESPONSE:\", result_3[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Combined query\n",
    "Explain: we can combine many tasks in one question.  \n",
    "For example: we can ask the agent to check inventory for product A. If it is out of stock, place order with the manufactor. After that update the quantity of product A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- EXAMPLE 4: Combined Query ---\")\n",
    "user_input_4 = \"Check if widget-b is still out of stock, and if not schedule a delivery for order #98765.\"\n",
    "result_4 = agent_app.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input_4}]},\n",
    "    config={\"configurable\": {\"thread_id\": THREAD_ID}}\n",
    ")\n",
    "print(\"AGENT RESPONSE:\", result_4[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
